{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imres_data_split.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiEe0-9rO0Mp",
        "outputId": "fb356e02-06a2-428c-f4e8-0ad1a67f823f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqI4U482PCOY",
        "outputId": "db55ca0d-47b6-4ce6-af12-3dd740c15261"
      },
      "source": [
        "%cd gdrive/MyDrive/petrobras2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/petrobras2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCa3MafmPEIH",
        "outputId": "a2fe32e7-ff27-4c02-eede-899a8b57be95"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\timres_data_setup.py  imres_train.py\n",
            "imres_data_setup.ipynb\timres_data_split.py  mask_rcnn_coco.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7epQQ0SPIwM"
      },
      "source": [
        "# ====================================================================\r\n",
        "# **Projeto de Classificação da Qualidade de Perfis de Imagem LWD**\r\n",
        "\r\n",
        "# Script para segregar as imagens em um set de treino e outro de teste\r\n",
        "\r\n",
        "# Data: Outubro de 2020\r\n",
        "# Autor: Ralph Piazza \r\n",
        "# ===================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNDhjDEyPQUz"
      },
      "source": [
        "# import libraries\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "from os import listdir\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU3M86VYPYWj"
      },
      "source": [
        "# global definitions\r\n",
        "\r\n",
        "ANNOT_DIR = 'data/annots/'\r\n",
        "SPLIT_DEST = 'data/'\r\n",
        "\r\n",
        "TOLERANCE = 0.25"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur5vHLvHPav5"
      },
      "source": [
        "# check whether the attempted split generated balanced sets\r\n",
        "\r\n",
        "def check_balance(train_img, df_img_info, fracs):      \r\n",
        "    tlength_1 = 1\r\n",
        "    tlength_2 = 1\r\n",
        "    tlength_3 = 1\r\n",
        "    for i in train_img:\r\n",
        "        class_info = df_img_info.loc[[i + 1]]\r\n",
        "        for index, row in class_info.iterrows(): \r\n",
        "            if(row['CLASS'] == 1):\r\n",
        "                tlength_1 += row['BB_LENGTH']\r\n",
        "            elif(row['CLASS'] == 2):\r\n",
        "                tlength_2 += row['BB_LENGTH']\r\n",
        "            elif(row['CLASS'] == 3):\r\n",
        "                tlength_3 += row['BB_LENGTH']        \r\n",
        "    \r\n",
        "    ttotal_length = tlength_1 + tlength_2 + tlength_3\r\n",
        "    \r\n",
        "    if (tlength_1 / ttotal_length < (1 + TOLERANCE) * fracs[0] and tlength_1 / ttotal_length > (1 - TOLERANCE) * fracs[0] and\r\n",
        "        tlength_2 / ttotal_length < (1 + TOLERANCE) * fracs[1] and tlength_2 / ttotal_length > (1 - TOLERANCE) * fracs[1] and\r\n",
        "        tlength_3 / ttotal_length < (1 + TOLERANCE) * fracs[2] and tlength_3 / ttotal_length > (1 - TOLERANCE) * fracs[2]):\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa2Wpv2UPdbd"
      },
      "source": [
        "# cycle through annotation files and consolidate the occurance of each class\r\n",
        "\r\n",
        "df_img_info = pd.DataFrame(columns=['IMAGE', 'CLASS', 'BB_LENGTH'])\r\n",
        "\r\n",
        "for annot_file in listdir(ANNOT_DIR):\r\n",
        "    df_annot_single = pd.read_csv(ANNOT_DIR + annot_file, decimal='.', sep=',', usecols=['CLASS', 'YMAX', 'YMIN'], index_col=False)\r\n",
        "    image_number = int(annot_file[0:5])    \r\n",
        "   \r\n",
        "    df_annot_single['BB_LENGTH'] = df_annot_single['YMAX'] - df_annot_single['YMIN'] + 1\r\n",
        "    df_annot_single = df_annot_single.drop(['YMAX', 'YMIN'], axis=1)\r\n",
        "    df_annot_single = df_annot_single.groupby(['CLASS']).sum()\r\n",
        "    df_annot_single.reset_index(inplace=True)\r\n",
        "    df_annot_single.insert(0, 'IMAGE', image_number)\r\n",
        "    \r\n",
        "    df_img_info = df_img_info.append(df_annot_single)    \r\n",
        "\r\n",
        "df_class_info = df_img_info.groupby(['CLASS']).sum('BB_LENGTH')\r\n",
        "df_class_info.reset_index(inplace=True)\r\n",
        "df_class_info = df_class_info.drop(['IMAGE'], axis=1)\r\n",
        "df_img_info = df_img_info.set_index('IMAGE')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4gh8MGsPf0F",
        "outputId": "c3b21eb4-838e-4d18-da50-6fbbca9e13cb"
      },
      "source": [
        "# select images to compose the train and test data sets\r\n",
        "\r\n",
        "total_length = df_class_info['BB_LENGTH'].sum()\r\n",
        "frac_1 = df_class_info.at[0, 'BB_LENGTH'] / total_length\r\n",
        "frac_2 = df_class_info.at[1, 'BB_LENGTH'] / total_length\r\n",
        "frac_3 = df_class_info.at[2, 'BB_LENGTH'] / total_length\r\n",
        "fracs = np.array([frac_1, frac_2, frac_3])\r\n",
        "\r\n",
        "img_list = np.array(range(1, image_number + 1))\r\n",
        "kfold = KFold(5, shuffle=True)\r\n",
        "run = 0\r\n",
        "for train_img, test_img in kfold.split(img_list):\r\n",
        "    run += 1\r\n",
        "    print(run)\r\n",
        "    if(check_balance(train_img, df_img_info, fracs)):\r\n",
        "        train_img += 1\r\n",
        "        test_img += 1\r\n",
        "        np.savetxt(SPLIT_DEST + 'train_list.txt', train_img, fmt = '%4u')\r\n",
        "        np.savetxt(SPLIT_DEST + 'test_list.txt', test_img, fmt = '%4u') \r\n",
        "        print(\"saving files\")       \r\n",
        "        break "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "saving files\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}